{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Perform the following operations using Python on the Telecom_Churn\n",
    "dataset. Compute and display summary statistics for each feature available\n",
    "in the dataset using separate commands for each statistic. (e.g. minimum\n",
    "value, maximum value, mean, range, standard deviation, variance and\n",
    "percentiles).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load Telecom_Churn dataset from a CSV file (replace the link with your dataset's file path)\n",
    "telecom_churn_csv = \"/content/Telecom Churn.csv\"\n",
    "data = pd.read_csv(telecom_churn_csv)\n",
    "\n",
    "# Displaying the first few rows of the dataset\n",
    "print(\"Dataset preview:\\n\", data.head())\n",
    "\n",
    "# Select numeric columns for statistical operations\n",
    "numeric_data = data.select_dtypes(include=[np.number])\n",
    "\n",
    "# Compute and display summary statistics for each feature\n",
    "for column in numeric_data.columns:\n",
    "    print(f\"\\nStatistics for feature: {column}\")\n",
    "\n",
    "    # Minimum value\n",
    "    print(f\"Minimum value: {numeric_data[column].min()}\")\n",
    "\n",
    "    # Maximum value\n",
    "    print(f\"Maximum value: {numeric_data[column].max()}\")\n",
    "\n",
    "    # Mean\n",
    "    print(f\"Mean: {numeric_data[column].mean()}\")\n",
    "\n",
    "    # Range (Max - Min)\n",
    "    feature_range = numeric_data[column].max() - numeric_data[column].min()\n",
    "    print(f\"Range: {feature_range}\")\n",
    "\n",
    "    # Standard Deviation\n",
    "    print(f\"Standard Deviation: {numeric_data[column].std()}\")\n",
    "\n",
    "    # Variance\n",
    "    print(f\"Variance: {numeric_data[column].var()}\")\n",
    "\n",
    "    # Percentiles (25th, 50th, and 75th)\n",
    "    percentiles = numeric_data[column].quantile([0.25, 0.50, 0.75])\n",
    "    print(f\"Percentiles (25th, 50th, 75th):\\n{percentiles}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Perform the following operations using Python on the data set\n",
    "House_Price Prediction dataset. Compute standard deviation, variance and\n",
    "percentiles using separate commands, for each feature. Create a histogram\n",
    "for each feature in the dataset to illustrate the feature distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load House Price Prediction dataset (replace with your file path if available locally)\n",
    "house_price_csv = \"/content/House Data.csv\"\n",
    "data = pd.read_csv(house_price_csv)\n",
    "\n",
    "# Preview the dataset\n",
    "print(\"Dataset preview:\\n\", data.head())\n",
    "\n",
    "# Select numeric columns for analysis\n",
    "numeric_data = data.select_dtypes(include=[np.number])\n",
    "\n",
    "# Compute statistics for each feature\n",
    "for column in numeric_data.columns:\n",
    "    print(f\"\\nStatistics for feature: {column}\")\n",
    "\n",
    "    # Standard Deviation\n",
    "    std_dev = numeric_data[column].std()\n",
    "    print(f\"Standard Deviation: {std_dev}\")\n",
    "\n",
    "    # Variance\n",
    "    variance = numeric_data[column].var()\n",
    "    print(f\"Variance: {variance}\")\n",
    "\n",
    "    # Percentiles (25th, 50th, 75th)\n",
    "    percentiles = numeric_data[column].quantile([0.25, 0.50, 0.75])\n",
    "    print(f\"Percentiles (25th, 50th, 75th):\\n{percentiles}\")\n",
    "\n",
    "    # Create histogram\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(numeric_data[column].dropna(), bins=30, color='blue', alpha=0.7)\n",
    "    plt.title(f\"Histogram of {column}\")\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Use House_Price prediction dataset. Provide summary statistics (mean,\n",
    "median, minimum, maximum, standard deviation) of variables (categorical\n",
    "vs quantitative) such as- For example, if categorical variable is age groups\n",
    "and quantitative variable is income, then provide summary statistics of\n",
    "income grouped by the age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the House Price dataset\n",
    "url = '/content/House Data.csv'\n",
    "house_data = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(house_data.head())\n",
    "\n",
    "# Check unique entries in the 'price' column to identify issues\n",
    "print(house_data['price'].unique())\n",
    "\n",
    "# Clean and convert the 'price' column to numeric\n",
    "# Remove 'TL', commas, and other non-numeric characters\n",
    "house_data['price'] = house_data['price'].str.replace('TL', '', regex=False)\n",
    "house_data['price'] = house_data['price'].str.replace(',', '', regex=False)\n",
    "house_data['price'] = house_data['price'].str.extract('(\\d+)', expand=False)  # Extract only numeric values\n",
    "house_data['price'] = pd.to_numeric(house_data['price'], errors='coerce')  # Convert to float, set invalid entries to NaN\n",
    "\n",
    "# Drop rows with NaN prices (optional, depending on the requirement)\n",
    "house_data = house_data.dropna(subset=['price'])\n",
    "\n",
    "# Categorical variable: district, Quantitative variable: price\n",
    "grouped_stats = house_data.groupby('district')['price'].agg(['mean', 'median', 'min', 'max', 'std'])\n",
    "\n",
    "# Rename the columns for clarity\n",
    "grouped_stats.rename(columns={\n",
    "    'mean': 'Mean Price',\n",
    "    'median': 'Median Price',\n",
    "    'min': 'Minimum Price',\n",
    "    'max': 'Maximum Price',\n",
    "    'std': 'Standard Deviation'\n",
    "}, inplace=True)\n",
    "\n",
    "# Display the grouped summary statistics\n",
    "print(grouped_stats)\n",
    "\n",
    "# Save to a CSV file for reference if needed\n",
    "grouped_stats.to_csv('HousePrice_Summary_by_District.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. Write a Python program to display some basic statistical details like\n",
    "percentile, mean, standard deviation etc (Use python and pandas\n",
    "commands) the species of ‘Iris-setosa’, ‘Iris-versicolor’ and ‘Iris-versicolor’\n",
    "of iris.csv dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#19\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset\n",
    "url = '/content/IRIS.csv'\n",
    "iris_data = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(iris_data.head())\n",
    "\n",
    "# List unique species\n",
    "print(\"\\nUnique species in the dataset:\")\n",
    "print(iris_data['species'].unique())\n",
    "\n",
    "# Filter data for each species and compute descriptive statistics\n",
    "for species in iris_data['species'].unique():\n",
    "    print(f\"\\nStatistical details for {species}:\")\n",
    "    species_data = iris_data[iris_data['species'] == species]\n",
    "    stats = species_data.describe(percentiles=[0.25, 0.5, 0.75])\n",
    "    print(stats)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
